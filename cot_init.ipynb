{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2c683da2-5fca-45ed-915c-add0bb5b6ab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import time\n",
    "from src.utils import batch_generate, tokens_generate, run_inference\n",
    "from src.mem import check_memory\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import huggingface\n",
    "from datetime import datetime\n",
    "load_dotenv('secrets.env')\n",
    "\n",
    "with open(\"config/config.yaml\", \"r\") as f: \n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "model_str = 'deepseek_r1_qwendistill_1.5'\n",
    "eval_df = 'big_bench'\n",
    "\n",
    "ds = config['datasets'][eval_df]\n",
    "model_path = config['models'][model]['path']\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1f71afb9-81d8-4582-94cf-d861c80cefe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(ds['source'], ds['subset']).shuffle(config['seed'])\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path) \n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea557dc-0b4c-4c15-a0ec-735d5fdc4d39",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "Goal: test model performance on 100 BBH questions w/ chain of thought reasoning =D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec77470-8343-4a62-b7de-fcbb9685f2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset['train'][0:10])\n",
    "\n",
    "batches = batch_generate(df, ds['input_column'], ds['target_column'])\n",
    "tokens = tokens_generate(batches, tokenizer, device = 'mps')\n",
    "res = run_inference(model, tokens, tokenizer, time_tracking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0acfb6c4-ca10-45fc-ac6d-d68b3924a7c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(src.instruct)\n",
    "from src.instruct import apply_instruct_format\n",
    "\n",
    "test = apply_instruct_format(df['input'], model = model_str, is_math = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ba96e7db-bc94-4215-b384-22e9157ab826",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<im_start|>system\n",
      "You are an AI assistant specialized in logical and causal reasoning.<|im_end|>\n",
      "<|im_start|>user\n",
      "please reason step by step, and put your final answer within \\boxed{}. How would a typical person answer each of the following questions about causation?\n",
      "Joe was about to go pick up his child from a school in the suburbs. In the parking lot, he stopped to talk with friends. Because of this delay in picking up his son, Joe's neighbor, who waited 15 min for Joe to show up, took the child home in his car. On the way home, the neighbor's car was struck by a drunk driver. Joe's son, the only seriously hurt victim, received severe leg injuries. Joe's behavior stems from his talkativeness. He is the type of person who likes to talk to anybody, at any time. Sometimes his friends are bothered by this seemingly excessive talkativeness and they even complain about it occasionally. But, after they got to know him better, they realized that Joe's talkativeness was a basic trait of his personality. Thus, it was something he could not help, even when he tried hard. Did the drunk driver cause injury to Joe's son?\n",
      "Options:\n",
      "- Yes\n",
      "- No<|im_end|>\n",
      "<|im_start|>assistant<think>\n",
      "\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "24d39bc4-3a2d-44d5-a27f-eb37c8615a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<im_start|>system\n",
      "You are an AI assistant specialized in logical and causal reasoning.<|im_end|>\n",
      "<|im_start|>user\n",
      "please reason step by step, and put your final answer within \\boxed{}. How would a typical person answer each of the following questions about causation?\n",
      "Joe was about to go pick up his child from a school in the suburbs. In the parking lot, he stopped to talk with friends. Because of this delay in picking up his son, Joe's neighbor, who waited 15 min for Joe to show up, took the child home in his car. On the way home, the neighbor's car was struck by a drunk driver. Joe's son, the only seriously hurt victim, received severe leg injuries. Joe's behavior stems from his talkativeness. He is the type of person who likes to talk to anybody, at any time. Sometimes his friends are bothered by this seemingly excessive talkativeness and they even complain about it occasionally. But, after they got to know him better, they realized that Joe's talkativeness was a basic trait of his personality. Thus, it was something he could not help, even when he tried hard. Did the drunk driver cause injury to Joe's son?\n",
      "Options:\n",
      "- Yes\n",
      "- No<|im_end|>\n",
      "<|im_start|>assistant<think>\n",
      "\"\n",
      "Okay, so I need to figure out whether the drunk driver caused the injury to Joe's son.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(response[0], skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "77b19ee0-6baa-4cea-9442-8ba43b9fe4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(test[3], padding = True, truncation = True, return_tensors = 'pt').to(device)\n",
    "response = model.generate(**tokens, temperature = 0.6)\n",
    "full_response = tokenizer.decode(response[0], skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c83311d4-c838-4d9d-beca-42a63370c502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I need to figure out whether the drunk driver caused the injury to Joe's son based\""
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_response.replace(test[3], '').strip() # nice! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

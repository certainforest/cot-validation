{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c683da2-5fca-45ed-915c-add0bb5b6ab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from src.utils import batch_generate, tokens_generate, run_inference\n",
    "from src.mem import check_memory\n",
    "from src.instruct import apply_instruct_format\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import huggingface\n",
    "from datetime import datetime\n",
    "load_dotenv('secrets.env')\n",
    "\n",
    "with open(\"config/config.yaml\", \"r\") as f: \n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "model_str = 'deepseek_r1_qwendistill_7'\n",
    "eval_df = 'big_bench'\n",
    "\n",
    "ds = config['datasets'][eval_df]\n",
    "model_path = config['models'][model_str]['path']\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780e3e26-b92a-4065-8a3c-68f7af9d6143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71afb9-81d8-4582-94cf-d861c80cefe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:   0%|                                 | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(ds['source'], ds['subset']).shuffle(config['seed'])\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path) \n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5113969-a3b2-4baf-95e2-03d001ae700b",
   "metadata": {},
   "source": [
    "# Experiment 1: CoT Determinism (unsure if want to do) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea557dc-0b4c-4c15-a0ec-735d5fdc4d39",
   "metadata": {},
   "source": [
    "# Experiment 2: \"Check in\" (CoT logit analysis)\n",
    "For each token *t* in our chain of thought, we'll append the </think> tag which triggers a response. From there, we can calculate the probability of a model generating the correct answer at token *t* – this illustrates:\n",
    "<ul>(1) \"when\" in the reasoning chain the model starts to arrive at an answer;</ul>\n",
    "<ul>(2) whether answers are likely to be correct before the model wants to output the </think> tag;</ul>\n",
    "<ul>(3) whether special tokens like \"wait\" cause answer probability to improve afterwards.</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa743c34-c2e5-4871-be52-b71177c52285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜><｜User｜>\n",
      "“Answer the below question. Answer with only the final response without any additional words or phrases. Please reason step by step, and put your final answer within \\boxed{}.\n",
      "\n",
      " How would a typical person answer each of the following questions about causation?\n",
      "Janet is an employee in a factory. Since she works in the maintenance department, she knows how to grease and oil all of the machines in the factory. It is her responsibility to put oil into the machines. Kate is also an employee at the factory. While she works in the human resources department, she knows how to grease and oil all of the machines in the factory. If Janet does not put oil in the machines, it is not Kate's responsibility to do so. One day, Janet forgets to put oil in an important machine. Janet noticed that she did not put oil in the machine. Kate did not notice that Janet did not put oil in the machine, and Kate also did not put oil in the machine. The machine broke down a few days later. Did Kate not putting oil in the machine cause it to break down?\n",
      "Options:\n",
      "- Yes\n",
      "- No<｜Assistant｜><think>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset['train'][0:5])\n",
    "df['input'] = apply_instruct_format(df['input'], model = model_str, is_answer_format = True)\n",
    "\n",
    "print(df['input'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f951a22-e394-4eb8-b47e-4ff679159cca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation., ?it/s]\n",
      "inference: 100%|█████████████████████████████████| 1/1 [02:23<00:00, 143.63s/it]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset['train'][0:5])\n",
    "df['input'] = apply_instruct_format(df['input'], model = model_str, is_answer_format = True)\n",
    "\n",
    "batches = batch_generate(df, ds['input_column'], ds['target_column'])\n",
    "tokens = tokens_generate(batches, tokenizer, device = device\n",
    "res = run_inference(model, tokens, tokenizer, time_tracking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4f14ff2-ac07-4626-a8c2-3022b2880cb6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜User｜>\n",
      "“Answer the below question. Answer with only the final response without any additional words or phrases. Please reason step by step, and put your final answer within \\boxed{}.\n",
      "\n",
      " How would a typical person answer each of the following questions about causation?\n",
      "Janet is an employee in a factory. Since she works in the maintenance department, she knows how to grease and oil all of the machines in the factory. It is her responsibility to put oil into the machines. Kate is also an employee at the factory. While she works in the human resources department, she knows how to grease and oil all of the machines in the factory. If Janet does not put oil in the machines, it is not Kate's responsibility to do so. One day, Janet forgets to put oil in an important machine. Janet noticed that she did not put oil in the machine. Kate did not notice that Janet did not put oil in the machine, and Kate also did not put oil in the machine. The machine broke down a few days later. Did Kate not putting oil in the machine cause it to break down?\n",
      "Options:\n",
      "- Yes\n",
      "- No<｜Assistant｜><think>\n",
      "Okay, so I need to figure out whether Kate's failure to grease and oil the machine caused the breakdown. Let me break this down step by step.\n",
      "\n",
      "First, I know that Janet is in the maintenance department, which is responsible for greasing and oiling all machines. She's supposed to do this every day. On a particular day, Janet forgot to put oil in an important machine. She noticed it, but Kate didn't notice and also didn't put oil in it. The machine broke down a few days later.\n",
      "\n",
      "Now, the question is whether Kate's failure to grease and oil the machine caused the breakdown. I need to consider causation, which means there should be a cause-effect relationship.\n",
      "\n",
      "In this case, Janet's failure to grease the machine was her responsibility because she was in the maintenance department. She was supposed to take care of it. So, her absence of action should be a cause for the machine to break down.\n",
      "\n",
      "Kate, on the other hand, was in the human resources department, which is unrelated to the maintenance department. So, her failure to grease and oil the machine wasn't her responsibility. She didn't know what was wrong, which is a factor in causation.\n",
      "\n",
      "So, Janet's actions were her responsibility, and she did not take any steps to fix the machine. This should have led to the breakdown. Since Kate didn't do anything relevant to the issue, her lack of action isn't the cause.\n",
      "\n",
      "Therefore, the breakdown was caused by Janet's failure to grease the machine, which was her responsibility, not by Kate's failure.\n",
      "</think>\n",
      "\n",
      "The breakdown was caused by Janet's failure to grease the machine, which was her responsibility. \n",
      "\n",
      "Answer: Yes\n"
     ]
    }
   ],
   "source": [
    "print(res[0]['response'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91568f-01d4-41dc-9651-d3fb9375f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for result in res: \n",
    "    for single_response in result['response']:\n",
    "        cleaned = re.sub(r'^.*?<think>', '<think>', single_response, flags=re.DOTALL)\n",
    "        print(cleaned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
